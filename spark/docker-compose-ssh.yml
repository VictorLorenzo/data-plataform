version: "3"

services:
#-------------------------
# Spark Master Service
#-------------------------
  spark-master:
    hostname: spark-master
    container_name: spark-master
    build:
      context: .
      dockerfile: Dockerfile_ssh
    image: custom_spark:3.4.1  
    command: bin/spark-class org.apache.spark.deploy.master.Master &
          - /bin/bash 
          - -x
          - -o 
          - pipefail 
          - -c 
          - |
            /opt/bitnami/scripts/spark/run.sh &
            /opt/bitnami/spark/sbin/start-history-server.sh
            wait

    volumes:
        - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    #   - ./spark-config/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    ports:
      - "8082:8080"
      - "7077:7077"
      - "4046:4040"
    environment:
      SPARK_MODE: master
      SPARK_PUBLIC_DNS: localhost

#-------------------------
# Spark Worker Service
#-------------------------
  spark-worker-1:
    hostname: spark-worker-1
    container_name: spark-worker-1
    image: custom_spark:3.4.1
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=5g
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_WORKER_WEBUI_PORT=8089
      - SPARK_UI_PORT=4046      
    ports:
      - '4040:4040'
    command: 
      - /bin/bash 
      - -x
      - -o 
      - pipefail 
      - -c 
      - |
        /opt/bitnami/scripts/spark/run.sh &
        sleep 10s
        env | cat >> /home/spark_user/docker_env.txt
        echo Spark123@ | sudo -S service ssh start
        wait
    volumes:
      -  spark_ssh_cache:/opt/bitnami/spark/cache_ivy/
      - ./spark-apps:/opt/bitnami/spark/dev/scripts    
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf  
      - ./spark-config/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml  
    depends_on:
      - spark-master

  spark-worker-2:
    hostname: spark-worker-2
    container_name: spark-worker-2
    image: custom_spark:3.4.1
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=5g
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_WORKER_WEBUI_PORT=8090
      - SPARK_UI_PORT=4046     
    ports:
      - '4041:4040'
    command: 
      - /bin/bash 
      - -x
      - -o 
      - pipefail 
      - -c 
      - |
        /opt/bitnami/scripts/spark/run.sh &
        sleep 10s
        env | cat >> /home/spark_user/docker_env.txt
        echo Spark123@ | sudo -S service ssh start
        wait
    volumes:
      -  spark_ssh_cache:/opt/bitnami/spark/cache_ivy/
      - ./spark-apps:/opt/bitnami/spark/dev/scripts   
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark-config/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml                    
    depends_on:
      - spark-master

  spark-worker-3:
    hostname: spark-worker-3
    container_name: spark-worker-3
    image: custom_spark:3.4.1
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=5g
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_WORKER_WEBUI_PORT=8091
      - SPARK_UI_PORT=4046     
    ports:
      - '4042:4040'
    command: 
      - /bin/bash 
      - -x
      - -o 
      - pipefail 
      - -c 
      - |
        /opt/bitnami/scripts/spark/run.sh &
        sleep 10s
        env | cat >> /home/spark_user/docker_env.txt
        echo Spark123@ | sudo -S service ssh start
        wait
    volumes:
      -  spark_ssh_cache:/opt/bitnami/spark/cache_ivy/
      - ./spark-apps:/opt/bitnami/spark/dev/scripts
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark-config/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml                 
    depends_on:
      - spark-master    

  spark-worker-4:
    hostname: spark-worker-4
    container_name: spark-worker-4
    image: custom_spark:3.4.1
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=5g
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_WORKER_WEBUI_PORT=8092
      - SPARK_UI_PORT=4046     
    ports:
      - '4043:4040'
    command: 
      - /bin/bash 
      - -x
      - -o 
      - pipefail 
      - -c 
      - |
        /opt/bitnami/scripts/spark/run.sh &
        sleep 10s
        env | cat >> /home/spark_user/docker_env.txt
        echo Spark123@ | sudo -S service ssh start
        wait
    volumes:
      -  spark_ssh_cache:/opt/bitnami/spark/cache_ivy/
      - ./spark-apps:/opt/bitnami/spark/dev/scripts
      - ./spark-config/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./spark-config/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml                 
    depends_on:
      - spark-master 

volumes:
  spark_ssh_cache: {}

networks:
  default:
    name: data-plataform
    external: true